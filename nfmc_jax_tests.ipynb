{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdcea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/richard/nfmc_jax/')\n",
    "import nfmc_jax\n",
    "import arviz as az\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chaospy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada79f5",
   "metadata": {},
   "source": [
    "# 1d Gaussian likelihood and prior test for nfmc_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab1e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(x, mu=0, sigma=1):\n",
    "    return -0.5 * jnp.log(2 * np.pi * sigma ** 2) - 0.5 * (x - mu) ** 2 / (2 * sigma ** 2)\n",
    "\n",
    "def log_prior(x):\n",
    "    return -0.5 * jnp.log(2 * np.pi * 5.0 ** 2) - 0.5 * (x) ** 2 / (2 * 5.0 ** 2)\n",
    "\n",
    "key = jax.random.PRNGKey(100)\n",
    "prior_samples = jax.random.multivariate_normal(key, mean=jnp.array([0.0]), \n",
    "                                               cov=jnp.array([[5.0]]), shape=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca581c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage:  0\n",
      "theta0:  [[ 0.7025566 ]\n",
      " [-1.5459814 ]\n",
      " [-0.6087517 ]\n",
      " [ 0.86115724]\n",
      " [ 1.7978467 ]\n",
      " [ 2.2860527 ]\n",
      " [ 0.7708193 ]\n",
      " [ 2.126035  ]\n",
      " [-0.8433591 ]\n",
      " [ 1.8386974 ]]\n",
      "Initialization logZ: -1.374, ESS/N: 0.873, logZ_pq: -1.355 log mean loss: -9.788\n",
      "Stage:  1\n",
      "No weights in the fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/nfmc_jax/nfmc_jax/nfo/nfo.py:293: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448222085/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  self.nf_model = GIS(torch.from_numpy(np.asarray(self.samples)),\n",
      "/home/richard/nfmc_jax/nfmc_jax/sinf/SIT.py:428: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448222085/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1940.)\n",
      "  Q, R = torch.qr(wi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta =  1\n",
      "weighting fit\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [10, 10] at index 1 does not match the shape of the indexed tensor [10, 1] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-97eb034d996e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trace = nfmc_jax.opt_nfo(log_like, log_prior, prior_samples, log_like_args=(0, 1), \n\u001b[0m\u001b[1;32m      2\u001b[0m                          pmap_backend=None, n0=10, iteration=5)\n",
      "\u001b[0;32m~/nfmc_jax/nfmc_jax/nfo/opt_nfo.py\u001b[0m in \u001b[0;36mopt_nfo\u001b[0;34m(log_like_func, log_prior_func, init_samples, log_like_args, pmap_backend, n0, k_trunc, eps_z, nf_iter, N, t_ess, g_AF, aN, bN, beta_max, bounds, N_temp, frac_validate, iteration, alpha, verbose, n_component, interp_nbin, KDE, bw_factor_min, bw_factor_max, bw_factor_num, edge_bins, ndata_wT, MSWD_max_iter, NBfirstlayer, logit, Whiten, batchsize, nocuda, patch, shape, random_seed)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopt_nfo_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     (\n\u001b[1;32m    168\u001b[0m         \u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nfmc_jax/nfmc_jax/nfo/opt_nfo.py\u001b[0m in \u001b[0;36mopt_nfo_int\u001b[0;34m(log_like_func, log_prior_func, init_samples, log_like_args, pmap_backend, n0, k_trunc, eps_z, nf_iter, N, t_ess, g_AF, aN, bN, beta_max, bounds, N_temp, frac_validate, iteration, alpha, verbose, n_component, interp_nbin, KDE, bw_factor_min, bw_factor_max, bw_factor_num, edge_bins, ndata_wT, MSWD_max_iter, NBfirstlayer, logit, Whiten, batchsize, nocuda, patch, shape, random_seed, _log)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m'''/         APPROXIMATE         /'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;34m'''///////////////////////////////'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mnfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_nf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#weighted fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0mqw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf_model_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mtheta_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogq_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nfmc_jax/nfmc_jax/nfo/nfo.py\u001b[0m in \u001b[0;36mfit_nf\u001b[0;34m(self, weighted)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mfit_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_ess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msinf_logw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 self.nf_model = GIS(torch.from_numpy(np.asarray(self.samples)),\n\u001b[0m\u001b[1;32m    294\u001b[0m                                     \u001b[0mweight_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                                     \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nfmc_jax/nfmc_jax/sinf/GIS.py\u001b[0m in \u001b[0;36mGIS\u001b[0;34m(data_train, data_validate, iteration, weight_train, weight_validate, n_component, interp_nbin, KDE, bw_factor, alpha, edge_bins, ndata_wT, MSWD_max_iter, NBfirstlayer, logit, Whiten, batchsize, nocuda, patch, shape, verbose)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_wT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata_wT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndata_wT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSWD_max_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSWD_max_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_spline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKDE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKDE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbw_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m#update the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nfmc_jax/nfmc_jax/sinf/SIT.py\u001b[0m in \u001b[0;36mfit_spline\u001b[0;34m(self, data, weight, edge_bins, derivclip, extrapolate, alpha, noise_threshold, MSWD_p, KDE, bw_factor, batchsize, verbose)\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0mdata0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [10, 10] at index 1 does not match the shape of the indexed tensor [10, 1] at index 1"
     ]
    }
   ],
   "source": [
    "trace = nfmc_jax.opt_nfo(log_like, log_prior, prior_samples, log_like_args=(0, 1), \n",
    "                         pmap_backend=None, n0=10, iteration=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974a56e",
   "metadata": {},
   "source": [
    "# Prior samples sanity check ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74969195",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "n_iter=1 #sinf iterations \n",
    "n_prior = 10#number of sobol points\n",
    "n_samples = n_prior #not used explicitly\n",
    "n0=n_prior\n",
    "N=n_samples\n",
    "#get sobol sequence for initial samples\n",
    "low,high=-1.0,1.0\n",
    "dist1d = chaospy.Iid(chaospy.Uniform(lower=low,upper=high),n)\n",
    "init_prior=dist1d\n",
    "init_prior = np.atleast_2d(dist1d.sample(n_prior,rule='sobol')).T\n",
    "# init_prior=None\n",
    "transform=None#'ahh'#'ahh' #turn off pymc3 transform \n",
    "if(transform is not None):\n",
    "    trname='t'\n",
    "    #logit( (x-a) / (b-a) )\n",
    "    init_prior = None#inv_logit(init_prior,low,high)#logit((init_prior-low) /(high-low))\n",
    "else:\n",
    "    trname='nt'\n",
    "knots=None#100 #default None\n",
    "bw=0.5#None#1.#None#0.5#1. #default 2.0\n",
    "redraw=False #don't redraw samples at every iteration, my local change\n",
    "layers=2\n",
    "ktrunc=np.inf #currently SKIPPING\n",
    "bw_use_pq=True #whether to use pq loss in determining bw\n",
    "t_ess=0.5\n",
    "g_AF=1\n",
    "aN=int(2*N)#10\n",
    "bN=1#2#int(N/2)\n",
    "beta_max=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c23a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(init_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88431ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
